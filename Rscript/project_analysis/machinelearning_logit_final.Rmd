---
title: "Logistic Regression "
author: "yoda"
date: "2017년 9월 3일"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### 1. 로지스틱 회귀분석
일반 회귀분석과 동일하게 종속변수와 독립변수 간의 관계를 나타내어 

향후 예측 모델을 생성하는데 있다.

일반 회귀분석과의 차이점은 종속변수에 연속형 대신 범주형 데이터를 대상으로 하며 

입력데이터가 주어졌을 경우, 특정 분류로 나눠지기 때문에 분류분석 방법으로 분류된다.

여기서는 판매여부 변수인 SOLD를 종속변수로 하여 데이터 중 70%를 훈련데이터로, 30%를 

테스트데이터로 나누어서 분석을 실행한다.


### 2. 데이터 로딩 및 확인

```{r}
data1 <- read.csv("perfact2.csv")
str(data1)
```

데이터 개요에서 설명한 데이터를 그대로 사용한다.(총 38912개 관측치, 15개 변수) 


### 3. 변수타입 변환 및 연속형변수 표준화
```{r}
# 연속형 변수의 타입 변환
data1$POSTDATE <- as.numeric(as.Date(data1$POSTDATE))
data1$RELPRICE   <- as.numeric(data1$RELPRICE)
data1$FALLRATE <- as.numeric(data1$FALLRATE)
data1$RELDATE <- as.numeric(as.Date(data1$RELDATE))
data1$POSTPRICE <- as.numeric(data1$POSTPRICE)

# 연속형 변수의 표준화
data1$RELPRICE   <- scale(data1$RELPRICE)
data1$FALLRATE <- scale(data1$FALLRATE)
data1$POSTDATE <- scale(data1$POSTDATE)
data1$RELDATE <- scale(data1$RELDATE)
data1$POSTPRICE <- scale(data1$POSTPRICE)
```

종속변수 판매여부(SOLD)를 설명하는 변수인 POSTPRICE, POSTDATE, FALLRATE, RELPRICE, RELDATE의 

단위가 다르기 때문에 표준화를 해야한다.

표준화방법에는 scale()을 통한 z변환, min값과 max값을 이용하는 [0~1]변환이 있으며 여기서는 

z변환을 사용한다.


### 3. 훈련데이터와 테스트데이터 나누기

```{r}
install.packages("caret")
library(caret)
library(Hmisc)

# SOLD 변수의 yes/no 빈도수 확인
describe(data1$SOLD)

# 훈련데이터 7 : 테스트데이터 3
part<-createDataPartition(data1$SOLD,p=0.7)
ind.train<-part$Resample1
data2.train<-data1[ind.train,]
data2.test<-data1[-ind.train,]
```


### 4. 훈련데이터 7 : 테스트데이터 3 비율로 나눈 후 확인
```{r}
describe(data2.train$SOLD)
describe(data2.test$SOLD)
```


### 5. 훈련데이터로 로지스틱 회귀분석 실행
```{r}
names(data1)
train_logit <- glm(SOLD~KRNAME+GB+CONTRACT+GUARANTEE+CHANGES
                   +CONDITIONS+COMPONENT+POSTDATE, family=binomial, data=data2.train)

# 다중공선성이 높은 변수를 순차적으로 제거 
vif(train_logit)

# 오즈비 확인
exp(coef(train_logit))
```

KRNAME변수의 아이폰 5C가 약 2.95배로 판매가능성에 가장 많은 영향을 주고 있다.


### 6. 훈련데이터로 나온 결과를 토대로 테스트데이터 로지스틱회귀분석 실행
```{r}
test.pred <- predict(train_logit, newdata=data2.test, type="response")
```

```{r}
plot(test.pred)
```


### 7. 훈련데이터의 로지스틱회귀분석의 최적모델을 찾기 위해 stepwise 실행
```{r}
train_logit.step <- step(train_logit, direction="both")
```

변수를 하나씩 제거하면서 최적 모델을 찾음.

AIC는 모형의 설명력을 나타내는 척도로 값이 작을수록 유의한 모형이다.


종속변수(SOLD) 판매여부에 유의한 변수는 다음과 같다.
```{r}
formula(train_logit.step)
```


### 8. 훈련데이터의 STEPWISE를 통해 구한 최적모델을 통해 다시 훈련용데이터 로지스틱회귀분석 실행
```{r}
train_logit.best <- glm(formula(train_logit.step), family=binomial, data=data2.train)
summary(train_logit.best)
```


### 9. 훈련용데이터를 통해 얻은 최적모델로 테스트데이터 로지스틱회귀분석 실행
```{r}
test.pred.best <- predict(train_logit.best, newdata=data2.test, type="response")
test.pred.best2 <- prediction(test.pred.best, data2.test$SOLD)
head(test.pred.best, 20)
plot(test.pred.best)
```


### 10. data2.test의 판매여부(SOLD)를 타겟으로 설정하고 예측 성능 확인
```{r}
test_target <- data2.test$SOLD
lr_trn_predicted <- rep(0, length(test_target))
lr_trn_predicted[which(test.pred.best >= 0.4)] <- 1

# 판매완료면 1, 아니면 0으로 설정
data2.test$SOLD2 <- ifelse(data2.test$SOLD=="yes", 1, 0)

# 성능확인

library(e1071)
confusionMatrix(lr_trn_predicted,data2.test$SOLD2)
```

Accuracy는 전체 정확도를 뜻하며 약 61%의 정확도를 가지고 있다.

Sensitivity는 실제로 값이 0일 경우에 0이라고 예측할 확률

Specificity는 실제로 값이 1일 경우에 1이라고 에측할 확률 

Pos Pred Value는 0으로 예측했는데 실제로 0일 확률

Neg Pred Value는 1로 예측했는데 실제로 1일 확률 

0(SOLD no)는 예측을 잘 했으나 1(SOLD yes)에 대한 예측의 정확도가 떨어진다.

이는 SOLD 변수의 값들이 신뢰성이 떨어지거나 표본수 부족 또는 독립변수와의 관계를 

원인으로 판단할 수 있다. 


### 11. AUC 확인
```{r}
install.packages("ROCR")
library(ROCR)
df_pred2 <- prediction(test.pred.best, data2.test$SOLD2)
plot(performance(df_pred2, "tpr", "fpr"))
performance(df_pred2, "auc")
auc <- performance(test.pred.best2, measure="auc")
auc <- auc@y.values[1]
auc
```

0.6306097의 예측률로 예측이 제대로 되지 않음을 알 수 있다.

excellent = 0.9~1

good = 0.8~0.9

fair = 0.7~0.8

poor = 0.6~0.7

fail = 0.5~0.6

# 모델링 & 분석 - 차원축소
```{r}

anova(train_logit, test="Chisq")
```

KRNAME과 GB, CONTRACT, CONDITIONS, COMPONENT가 유의하다.

```{r}
# 유의한 변수로 다시 로지스틱 분석 실행 
train_logit2 <- glm(SOLD ~ KRNAME+GB+CONTRACT+CONDITIONS+COMPONENT, data=data2.train, family="binomial")

# anova로 전 모델과 비교
anova(train_logit2, train_logit, test="Chisq")
```

p값이 0.094이며 Residual Deviance도 33782에서 33792로 크게 변하지 않아 예측도가 크게
달라지지 않을꺼라 예상된다.

# ROC 커브 확인
```{r}
test.pred2.best <- predict(train_logit2, newdata=data2.test, type="response")
test.pred2.best2 <- prediction(test.pred2.best, data2.test$SOLD) 
test.pred.prf <- performance(test.pred.best2, measure = "tpr", x.measure = "fpr")
test.pred2.prf <- performance(test.pred2.best2, measure = "tpr", x.measure = "fpr") 
plot(test.pred.prf) 
plot(test.pred2.prf, add = TRUE, colorize = TRUE)
```

두 커브선이 겹쳐보이는 것으로 보아 비슷한 결과가 나온다.
